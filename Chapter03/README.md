# Chapter 3: Making Decisions with Linear Equations

The linear models are possibly the most commonly used algorithms in statistics and machine learning. They are used for both regression and classification. Thus, in this chapter we will start by looking into the basic least-squares algorithm, then will move on to more advanced algorithms as the chapter progresses. 

The secondary topics that you will get introduced to in parallel to the linear model are regularisation and regression intervals. Regularisation is a very powerful concept that you will meet over and over again throughout your machine learning journey. Thus, I decided to introduce it early on in the book. The concept of regression intervals is also a very useful tool to quantify your uncertaining about your productions. 

By the end of this chapter, you will have a very good understanding of the following topics:
- Understanding linear models and their history
- Learn about regression models evaluations criteria (MSE, MAE and R^2)
- How to engineer new features and find their Importances (e.g. Polynomial features)
- What is regularisation? What are solvers? 
- Using your first Generalised Linear Model, i.e. Logistic regression
- Additional linear models (Stochastics Gradient Descent, Elastic-net, RANSAC, etc)
- Finding regression intervals


